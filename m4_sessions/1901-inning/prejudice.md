## Group Members:
Tanjie, Melvin, Derek, Harper

## Name of Session: 
Prejudice

## Session Description 
Turing's mission is to unlock human potential by training a diverse, inclusive student body to succeed in high-fulfillment technical careers. In this session we will identify, examine, and discuss our prejudices, biases, and our related experiences with the aim of creating concrete actionable solution to make tech and our broader communities more (inclusive**?)

## Session Outcomes 
(What will students learn/leave with?): 
Students will leave with a concrete plan for address their own biases and those of others in the wild

## Session Outline
* Intros (5-10 mins) Let students settle in the space, an icebreaker where each student writes an interesting fact about themselves on a piece of paper and puts it in a hat. Papers are drawn by a facilitator, the fact is read aloud and the group tries to guess who submitted the fact.  Norms and expectations will then be outlined. 

* Implicit Bias Tests (10 - 15 mins) Students will need to bring a computer to this session.  Facilitators will choose four implicit bias tests.  Students will be randomly assigned to take one of the four test, and time permitting, will be able to another bias test of their choosing. Students will be given a few minutes to reflect on the finding either in a journal or just to themselves.

* Small Group Discussion (15 mins) Students will break into small groups determined by the randomly assigned bias test (eg, those who took the bias around disabilities test will group together, those who took the racial biases test will group, etc.
The facilitators will write discussion questions on the white board in order to lead focused discussion. All facilitators will have taken a bias test beforehand, and will be prepared to speak aobut their experiences while taking it with their groups.

* Recap and Segue (5 min) Come back together to a larger group, where facilitators will invite students to share insights from their break out discussions.  Facilitator will then provide a link to short article on bias in technology (Article currently TBD, but will center around bias in AI, eg, the racist twitter bot).

* Time allotment for reading the article (5 min)

* Discussion (20 mins) led by all 3 group members.  Discuss how this related to tech.  Start with broad example like racist twitterbot and then bring it down to a more personal level with examples from Turing.  Ask what are steps to take when things like this happen in your community.  Brainstorm potential reactions/actions to be better prepared to confont bias when it presents itself. 

## Norms
* Listen
* Take people's stories at face value - no questioning authenticity/experience
* Check reactions when listening - don't make the story about you when it's someone else's story
* Frame when/how to use words that may be offensive - leaders give personal example
* Suggest parking lot for later discussions

## Questions for Small Groups
* what tests did you take?
* did your results surprise you?
* Do you have internalized prejudice? (If you took a test that you share a diversty marker with)
* When have you been a target of prejudice?  Alternately, when have you been complicit (through action or inaction)?

## Larger Group Takeaways
* If someone confronts you about a particular situation where they felt marginalized and you contributed to this feeling, don't make them process your feelings about the situation.  It's not their job to comfort you, it's your job to listen, and take feedback.
* Turing is not immune to biases and prejudice.  It happens here. 
* If you have identified a prejudice you hold, what can you actively do to counteract or stop it? (short term counteracted by being exposed to alternatives to their particular prejudice - seek out things that challenge your particular bias)
## Materials
[Harvard's Implicit Bias Test](https://implicit.harvard.edu/implicit/takeatest.html)

And One of the following:

[The Guardian - AI programs exhibit racial and gender biases, research reveals](https://www.theguardian.com/technology/2017/apr/13/ai-programs-exhibit-racist-and-sexist-biases-research-reveals)

[The impact of gender and race bias in AI](https://blogs.icrc.org/law-and-policy/2018/08/28/impact-gender-race-bias-ai/)

[Artificial Intelligence Has a Bias Problem, and It's Our Fault](https://www.pcmag.com/article/361661/artificial-intelligence-has-a-bias-problem-and-its-our-fau)

[Unmasking A.I.'s Bias Problem](http://fortune.com/longform/ai-bias-problem/)


## Group Notes from 1/25
-Intro with snacks and have them pick an implicit bias out of a fishbowl
-Students write on the back of their paper about a insteresting topic
-Introduce ourselves 
-Start out with the Implicit Bias Test (split students into three groups and assign each group a specific bias test to take)
-Model (have Gear Up leaders take test beforehand and model 
externally reflecting on the results we get) 
-Set ground rules for big group discussion 
-Have students work in groups to discuss mark down small group discussions
-Come together to share big group discussions
-Introduce article about racist Bots and bias in AI development
-Come up with strategies as a group for advocating for a diverse tech community



-What are our learning goals? What kinds of guiding questions could we ask that are related to learning goals?
-Help students create concrete action steps for post-session awakening
-Introduce discussion about AI bias 
-Make a bridge to making students into advocates for tech diversity 


Submit a PR at the end of this session and tag @emhickmann
